{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run this notebook locally, you must install gcloud \n",
    "# and authenticate with your Google Cloud account by running `gcloud auth application-default login`.\n",
    "\n",
    "import os\n",
    "import base64\n",
    "import csv\n",
    "import google.generativeai as genai\n",
    "import re\n",
    "import time\n",
    "\n",
    "# Configure the API\n",
    "genai.configure(api_key=\"Add_your_API_key_here\")\n",
    "\n",
    "# Define the generative model\n",
    "model = genai.GenerativeModel(\"gemini-1.5-pro-latest\", generation_config={\"temperature\": 0})\n",
    "\n",
    "# Folder containing the PDFs\n",
    "pdf_folder = \"Add/Your/Path/Here\"\n",
    "\n",
    "# Output CSV file\n",
    "output_csv = os.path.join(pdf_folder, \"responses.csv\")\n",
    "\n",
    "# Define the prompt\n",
    "prompt = (\n",
    "    \"Please provide the contributions of this article in the following exact format, ensuring no deviations:\\n\\n\"\n",
    "    \"Here's a paragraph summarizing the contributions of the article, \\\"<Title of the Article>\\\":\\n\\n\"\n",
    "    \"<Detailed Contributions in paragraph form (no enumeration, no bullet points, and no additional formatting)>\\n\\n\"\n",
    "    \"IMPORTANT: Ensure there are exactly two newline breaks (`\\\\n\\\\n`) before the contributions section. Do not modify the format.\"\n",
    ")\n",
    "\n",
    "# List to store responses\n",
    "responses = []\n",
    "\n",
    "# Retry settings\n",
    "MAX_RETRIES = 5  # Maximum retry attempts per file\n",
    "INITIAL_WAIT = 2  # Initial wait time in seconds (for exponential backoff)\n",
    "\n",
    "# Loop through all PDF files in the folder\n",
    "for pdf_file in os.listdir(pdf_folder):\n",
    "    if pdf_file.endswith(\".pdf\"):  \n",
    "        pdf_path = os.path.join(pdf_folder, pdf_file)\n",
    "        print(f\"Processing: {pdf_path}\")\n",
    "\n",
    "        retry_count = 0\n",
    "        while retry_count < MAX_RETRIES:\n",
    "            try:\n",
    "                # Read and encode the PDF file in base64\n",
    "                with open(pdf_path, \"rb\") as doc_file:\n",
    "                    doc_data = base64.standard_b64encode(doc_file.read()).decode(\"utf-8\")\n",
    "\n",
    "                # Generate content using the model\n",
    "                response = model.generate_content([{'mime_type': 'application/pdf', 'data': doc_data}, prompt])\n",
    "                print(response.text)\n",
    "\n",
    "                # Extract title\n",
    "                title_match = re.search(r'Here\\'s a paragraph summarizing the contributions of the article, \"(.*?)\"', response.text)\n",
    "                title = title_match.group(1) if title_match else \"Title not found.\"\n",
    "\n",
    "                # Extract contributions\n",
    "                contributions = response.text.split('\\n\\n', 1)[1] if \"\\n\\n\" in response.text else \"Contributions not found.\"\n",
    "\n",
    "                # Append to responses\n",
    "                responses.append([pdf_file, title, contributions])\n",
    "                break  # Exit retry loop if successful\n",
    "\n",
    "            except Exception as e:\n",
    "                retry_count += 1\n",
    "                wait_time = INITIAL_WAIT * (2 ** (retry_count - 1))  # Exponential backoff\n",
    "                print(f\"Error processing {pdf_file} (Attempt {retry_count}/{MAX_RETRIES}): {e}\")\n",
    "                if retry_count < MAX_RETRIES:\n",
    "                    print(f\"Retrying in {wait_time} seconds...\")\n",
    "                    time.sleep(wait_time)\n",
    "                else:\n",
    "                    print(f\"Skipping {pdf_file} after {MAX_RETRIES} failed attempts.\")\n",
    "                    responses.append([pdf_file, \"Error\", f\"Failed after {MAX_RETRIES} attempts: {e}\"])\n",
    "\n",
    "# Save responses to a CSV file\n",
    "with open(output_csv, mode=\"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "    writer.writerow([\"Filename\", \"Title\", \"Contributions\"])  \n",
    "    writer.writerows(responses)  \n",
    "\n",
    "print(f\"Responses saved to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input and output files\n",
    "input_csv = os.path.join(pdf_folder, \"responses.csv\")  # Input CSV with summarized responses\n",
    "output_csv = os.path.join(pdf_folder, \"relevant_articles.csv\")  # Output CSV for relevant articles\n",
    "irrelevant_csv = os.path.join(pdf_folder, \"irrelevant_articles.csv\") # Output CSV for irrelevant articles\n",
    "\n",
    "# Function to generate a relevance check prompt\n",
    "def generate_relevance_prompt(article_title, article_response):\n",
    "    return f\"\"\"\n",
    "    Based on the following summarized response of the article titled \"{article_title}\":\n",
    "\n",
    "    {article_response}\n",
    "\n",
    "    Is this article relevant to the topic of digital twins for intelligent traffic intersections? Answer with Yes or No and explain briefly.\n",
    "    \"\"\"\n",
    "\n",
    "# Read the input CSV and process each article\n",
    "relevant_data = []\n",
    "irrelevant_data = []\n",
    "\n",
    "with open(input_csv, mode=\"r\", encoding=\"utf-8\") as csv_file:\n",
    "    reader = csv.DictReader(csv_file)\n",
    "    for row in reader:\n",
    "        filename = row.get(\"Filename\", \"\")\n",
    "        title = row.get(\"Title\", \"Unknown Title\")\n",
    "        \n",
    "        # If the title is \"Title not found.\", use the filename as the title\n",
    "        if title == \"Title not found.\":\n",
    "            title = filename\n",
    "            \n",
    "        response = row.get(\"Contributions\", \"\")  # Use 'Contributions' as the description column\n",
    "        contribution = row.get(\"Contributions\", \"\")\n",
    "\n",
    "        # Generate relevance prompt\n",
    "        relevance_prompt = generate_relevance_prompt(title, response)\n",
    "\n",
    "        print(f\"Checking relevance for article: {title}\")\n",
    "        try:\n",
    "            # Check relevance\n",
    "            relevance_response = genai.GenerativeModel(\"gemini-1.5-pro-latest\", generation_config={\"temperature\": 0}).generate_content([relevance_prompt])\n",
    "            relevance_answer = relevance_response.text.strip().split(\"\\n\")[0].lower()\n",
    "\n",
    "            if \"yes\" in relevance_answer:\n",
    "                relevant_data.append({\"Filename\": filename, \"Title\": title, \"Contributions\": contribution, \"Response\": relevance_response.text})\n",
    "            else:\n",
    "                irrelevant_data.append({\n",
    "                    \"Title\": title,\n",
    "                    \"Reason\": relevance_response.text\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing article '{title}': {e}\")\n",
    "            irrelevant_data.append({\n",
    "                \"Title\": title,\n",
    "                \"Reason\": f\"Error: {e}\"\n",
    "            })\n",
    "\n",
    "# Save relevant articles to a CSV\n",
    "with open(output_csv, mode=\"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "    fieldnames = [\"Filename\", \"Title\", \"Contributions\", \"Response\"]\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(relevant_data)\n",
    "\n",
    "# Save irrelevant articles to a separate CSV\n",
    "with open(irrelevant_csv, mode=\"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "    fieldnames = [\"Title\", \"Reason\"]\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(irrelevant_data)\n",
    "\n",
    "print(f\"Relevant articles saved to {output_csv}\")\n",
    "print(f\"Irrelevant articles saved to {irrelevant_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output files\n",
    "relevant_csv = os.path.join(pdf_folder, \"relevant_articles.csv\")\n",
    "\n",
    "# Output files\n",
    "categorized_scores_csv = os.path.join(pdf_folder, \"categorized_articles_with_scores.csv\")\n",
    "final_categorized_csv = os.path.join(pdf_folder, \"final_categorized_articles.csv\")\n",
    "error_log_csv = os.path.join(pdf_folder, \"error_log.csv\")\n",
    "\n",
    "# Define themes\n",
    "themes = {\n",
    "    \"Digital Twin Architecture and Frameworks\": [\n",
    "        \"Focus on architectural/design considerations for digital twins\",\n",
    "        \"Emphasis on integration of diverse/heterogeneous data sources\",\n",
    "        \"Discusses scalability, interoperability, or standardization of frameworks\",\n",
    "        \"Addresses critical architectural considerations for seamless data integration\"\n",
    "    ],\n",
    "    \"Data Processing and Simulation Techniques\": [\n",
    "        \"Emphasis on data fusion, probabilistic modeling, or filtering methods\",\n",
    "        \"Focus on handling uncertainties (e.g., human behavior, environmental variability)\",\n",
    "        \"Proposes/evaluates advanced simulation techniques for safety/reliability\",\n",
    "        \"Discusses detailed methods of simulation development including calibration and validation\"\n",
    "    ],\n",
    "    \"Artificial Intelligence and Machine Learning in Traffic Control\": [\n",
    "        \"Focuses on AI/ML techniques for traffic management\",\n",
    "        \"Discusses creation of adaptive and intelligent systems\",\n",
    "        \"Explores robustness and scalability of AI/ML systems\",\n",
    "        \"Focuses on adaptive responses to real-world traffic complexities\"\n",
    "    ],\n",
    "    \"Safety and Vulnerable Road User Protection\": [\n",
    "        \"Centers on safety concerns for vulnerable road users\",\n",
    "        \"Discusses the role of digital twins in improving safety outcomes\",\n",
    "        \"Addresses ethical and societal considerations (e.g., equity, privacy)\",\n",
    "        \"Emphasizes policies/strategies for inclusive and ethical deployment\"\n",
    "    ],\n",
    "    \"Applications of Digital Twins in Smart Infrastructure\": [\n",
    "        \"Explores large-scale implementation of digital twins\",\n",
    "        \"Focuses on integration with smart infrastructure (e.g., IoT, connected vehicles)\",\n",
    "        \"Discusses challenges/advancements for scalability\",\n",
    "        \"Focuses on modernization of infrastructure networks with digital twins\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "def generate_scoring_prompt(article_title, article_response, themes):\n",
    "    theme_prompts = \"\\n\\n\".join([\n",
    "        f\"**{theme}**:\\n- {criteria[0]}\\n- {criteria[1]}\\n- {criteria[2]}\\n- {criteria[3]}\"\n",
    "        for theme, criteria in themes.items()\n",
    "    ])\n",
    "\n",
    "    return f\"\"\"\n",
    "    Based on the summarized response of the article titled \"{article_title}\":\n",
    "\n",
    "    {article_response}\n",
    "\n",
    "    Evaluate the relevance of this article for each theme based on the following criteria:\n",
    "\n",
    "    {theme_prompts}\n",
    "\n",
    "    Assign a numerical score from 1 to 10 for each theme, where:\n",
    "    - 1 means 'Not relevant at all'\n",
    "    - 10 means 'Highly relevant'\n",
    "\n",
    "    **Response Format:**  \n",
    "    Each theme must be followed by a score **on the same line** in this exact format:\n",
    "\n",
    "    ```\n",
    "    Digital Twin Architecture and Frameworks: X  \n",
    "    Data Processing and Simulation Techniques: X  \n",
    "    Artificial Intelligence and Machine Learning in Traffic Control: X  \n",
    "    Safety and Vulnerable Road User Protection: X  \n",
    "    Applications of Digital Twins in Smart Infrastructure: X  \n",
    "    ```\n",
    "\n",
    "    IMPORTANT: Only return the theme name and score. Do not add explanations, bullets, or extra text.\n",
    "    \"\"\"\n",
    "\n",
    "# Function to extract scores from LLM response\n",
    "def extract_scores(response_text, themes):\n",
    "    scores = {theme: 0 for theme in themes}  # Default all themes to 0\n",
    "\n",
    "    # Regex pattern to capture \"Theme: Score\" format\n",
    "    score_pattern = re.compile(r\"(.+?):\\s*(\\d+)\", re.MULTILINE)\n",
    "\n",
    "    matches = score_pattern.findall(response_text)\n",
    "\n",
    "    for theme, score in matches:\n",
    "        theme = theme.strip()\n",
    "        if theme in themes:  # Ensure extracted theme is valid\n",
    "            scores[theme] = int(score.strip())\n",
    "\n",
    "    return scores\n",
    "\n",
    "# Function to extract only the theme name from the tie-breaking response\n",
    "def extract_theme_name(response_text, themes):\n",
    "    for theme in themes.keys():\n",
    "        if theme in response_text:\n",
    "            return theme\n",
    "    return \"Unknown Theme\"  # Fallback if no theme is detected\n",
    "\n",
    "# Lists to store results\n",
    "categorized_scores = []\n",
    "final_categorized = []\n",
    "error_log = []\n",
    "\n",
    "with open(relevant_csv, mode=\"r\", encoding=\"utf-8\") as csv_file:\n",
    "    reader = csv.DictReader(csv_file)\n",
    "\n",
    "    for row in reader:\n",
    "        title = row.get(\"Title\", \"Unknown Title\")\n",
    "        response = row.get(\"Contributions\", \"\")\n",
    "        pdf_file = row.get(\"Filename\", \"\")\n",
    "\n",
    "        # Generate the scoring prompt\n",
    "        scoring_prompt = generate_scoring_prompt(title, response, themes)\n",
    "\n",
    "        print(f\"Scoring article: {title}\")\n",
    "        try:\n",
    "            # Generate scoring response\n",
    "            scoring_response = genai.GenerativeModel(\"gemini-1.5-pro-latest\", generation_config={\"temperature\": 0}).generate_content([scoring_prompt])\n",
    "            scoring_text = scoring_response.text.strip()\n",
    "\n",
    "            # Extract scores using the function\n",
    "            scores = extract_scores(scoring_text, themes)\n",
    "\n",
    "            # Save scores to categorized_scores\n",
    "            categorized_scores.append({\n",
    "                \"Title\": title,\n",
    "                \"Tie-breaker\": \"\",  # Default empty, will be updated if a tie occurs\n",
    "                **scores\n",
    "            })\n",
    "\n",
    "            # Determine the final category\n",
    "            max_score = max(scores.values())\n",
    "            top_categories = [theme for theme, score in scores.items() if score == max_score]\n",
    "\n",
    "            if len(top_categories) == 1:\n",
    "                final_category = top_categories[0]\n",
    "            else:\n",
    "                # Tie detected, ask Gemini to break the tie\n",
    "                tie_prompt = f\"\"\"\n",
    "                The following article has multiple themes with the highest score:\n",
    "\n",
    "                Title: {title}\n",
    "\n",
    "                Top themes: {', '.join(top_categories)}\n",
    "\n",
    "                Based on the summarized response, which theme is the best fit? Provide only the theme name, no explanation.\n",
    "                \"\"\"\n",
    "                tie_response = genai.GenerativeModel(\"gemini-1.5-pro-latest\", generation_config={\"temperature\": 0}).generate_content([tie_prompt])\n",
    "                \n",
    "                # Extract only the theme name\n",
    "                final_category = extract_theme_name(tie_response.text.strip(), themes)\n",
    "\n",
    "                # Save tie-breaker decision\n",
    "                categorized_scores[-1][\"Tie-breaker\"] = final_category  # Update last entry with the tie-breaker result\n",
    "\n",
    "            # Save final categorization\n",
    "            final_categorized.append({\n",
    "                \"Filename\": pdf_file,\n",
    "                \"Title\": title,\n",
    "                \"Final Category\": final_category\n",
    "            })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing article '{title}': {e}\")\n",
    "            error_log.append({\n",
    "                \"Title\": title,\n",
    "                \"Error\": str(e)\n",
    "            })\n",
    "\n",
    "# Save scored articles to a CSV\n",
    "with open(categorized_scores_csv, mode=\"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "    fieldnames = [\"Title\", \"Tie-breaker\"] + list(themes.keys())\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(categorized_scores)\n",
    "\n",
    "# Save final categorized articles to a CSV\n",
    "with open(final_categorized_csv, mode=\"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "    fieldnames = [\"Filename\", \"Title\", \"Final Category\"]\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(final_categorized)\n",
    "\n",
    "# Save errors to a separate CSV\n",
    "with open(error_log_csv, mode=\"w\", newline=\"\", encoding=\"utf-8\") as csv_file:\n",
    "    fieldnames = [\"Title\", \"Error\"]\n",
    "    writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(error_log)\n",
    "\n",
    "print(f\"Categorized articles with scores saved to {categorized_scores_csv}\")\n",
    "print(f\"Final categorized articles saved to {final_categorized_csv}\")\n",
    "print(f\"Errors logged in {error_log_csv}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
